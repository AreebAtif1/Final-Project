[
  {
    "objectID": "Sources.html",
    "href": "Sources.html",
    "title": "Sources",
    "section": "",
    "text": "Kaggle Dataset\n\n(https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)\n\nChatGPt\nDavid Kane’s course"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BMI and Diabetes",
    "section": "",
    "text": "BMI, otherwise known as body mass index is derived from the mass and height of a person which is used to categorize people into different weight groups. I gathered data from a kaggle dataset called “Pima Indians Diabetes Database” which got its data from the National Institute of Diabetes and Digestive and Kidney Diseases. using data from the National Institute of Diabetes and Digestive and Kidney Diseases, we seek to understand the correlation, if any, between different BMI levels and the risk of diabetes. We modeled BMI, a continuous variable, as a function of diabetes. People with higher than normal BMI are at a higher likelihood of developing diabetes. As depicted in the graph, the probability of having diabetes increases with BMI. This suggests that higher BMI is associated with a higher likelihood of developing diabetes. This aligns with well-established medical knowledge that excess body weight is a significant risk factor for diabetes.\n\n\n\n\n\n\n\n\n\nThe graph illustrates how the probability of having diabetes changes with BMI. The x-axis represents BMI values ranging from the lowest to the highest observed in our dataset, while the y-axis shows the predicted probability of diabetes. The blue line indicates the mean predicted probability, and the shaded area around it represents the 95% credible intervals, showing the range within which the true probability is likely to fall.\nIncreasing Risk with Higher BMI: As depicted in the graph, the probability of having diabetes increases with BMI. This suggests that higher BMI is associated with a higher likelihood of developing diabetes. This aligns with well-established medical knowledge that excess body weight is a significant risk factor for diabetes.\nSafe and Healthy BMI Range: The graph highlights that individuals with lower BMI values have a substantially lower probability of having diabetes. Therefore, maintaining a healthy BMI—typically considered to be between 18.5 and 24.9—can significantly reduce the risk of diabetes. Individuals with BMI values in this range are likely to have a much lower risk compared to those with higher BMI values.\nUncertainty and Recommendations: The shaded credible intervals provide a measure of uncertainty around the predictions. While the general trend shows increasing risk with higher BMI, the exact probability at any given BMI can vary. It’s essential to consider other factors like diet, physical activity, and genetics when evaluating diabetes risk. For individuals looking to reduce their diabetes risk, aiming for a BMI within the healthy range is a practical and effective strategy."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "My Name is Areeb Atif, I am a 17 year old rising senior from New Jersey. More of my work can be seen on my Github page (https://github.com/AreebAtif1).\nIf you need to reach me, my email is areebatif2007@gmail.com\nMy project is about how BMI and diabetes are correlated and at what level of BMI puts an individual at a great risk of diabetes. Here is the link to my Github Repo (https://github.com/AreebAtif1/Final-Project).\nThis project was created as a part of Kane’s Data Science Bootcamp https://bootcamp.davidkane.info/."
  },
  {
    "objectID": "Model.html",
    "href": "Model.html",
    "title": "Model",
    "section": "",
    "text": "Using a Bayesian regression model, and the formula \\[Risk∼β0​+β1​×BMI\\]\n\n\n Family: bernoulli \n  Links: mu = logit \nFormula: Outcome ~ BMI \n   Data: data (Number of observations: 768) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    -3.71      0.40    -4.50    -2.96 1.00     3212     2483\nBMI           0.09      0.01     0.07     0.12 1.00     3540     2521\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCertainly! Let’s break down the Bayesian logistic regression formula and its components:\n\n1. Model Formula\n\nLogistic Regression Model:\n[ (p) = _0 + _1 ]\nWhere: - ( p ) is the probability of the outcome (e.g., having diabetes). - ( (p) ) is the log-odds of the probability ( p ). The logit function is defined as: [ (p) = () ] This transformation converts probabilities (which are between 0 and 1) into a scale where the values can range from (-) to (+).\n\n**( _0 )** is the intercept of the model. It represents the log-odds of the outcome when all predictors are zero.\n**( _1 )** is the coefficient for the predictor variable (in this case, BMI). It measures how the log-odds of the outcome change with a one-unit change in BMI.\n\n\n\n\n2. Likelihood Function\n\nBinary Outcome:\n[ Y _0, _1, (p) ]\nWhere: - ( Y ) is the binary outcome variable (0 or 1). - ( p ) is the probability of ( Y = 1 ) given BMI, which is modeled using the logistic function: [ p = ] This is the inverse of the logit function and maps the log-odds back to a probability between 0 and 1.\n\n\n\n3. Priors\nIn Bayesian regression, you specify prior distributions for the model parameters before observing the data:\n\n**For the intercept (( _0 ))**: [ _0 (0, 10) ] This prior assumes that the intercept follows a normal distribution with mean 0 and standard deviation 10. This is a wide prior that allows a large range of possible intercept values.\n**For the coefficient (( _1 ))**: [ _1 (0, 10) ] Similarly, this prior assumes that the coefficient for BMI follows a normal distribution with mean 0 and standard deviation 10.\n\n\n\nSummary\n\nLogit Function: Transforms probability ( p ) to log-odds.\nLogistic Function: Converts log-odds back to a probability.\nLikelihood: Describes how the observed data ( Y ) is distributed given the parameters and predictor.\nPriors: Represent your beliefs about the parameters before seeing the data.\n\nThe Bayesian logistic regression model estimates the parameters ( _0 ) and ( _1 ) while incorporating prior beliefs about their distributions and updating these beliefs based on the observed data."
  }
]